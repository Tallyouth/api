# 期刊管理平台二期爬虫接口
------

## 接口描述
新增爬虫


### HTTP方法: POST

### 请求URL: 
    http://127.0.0.1:8000/v1/crawler

## 请求示例:
    {
    	"crawlerName": "crawler2",
    	"crawlerMaster": "yhb",
    	"seriesId": "8f557978c31211e9a205482ae31bec7c",
    	"crawlerFrequence": 8
    }

### 请求参数

|参数|是否必选|类型|描述
|-|-|-|-
|seriesId|是	|string	|爬虫对应的期刊id，唯一索引
|crawlerName|是	|string	|爬虫名称，唯一索引
|crawlerMaster|是	|string	|爬虫编写者，国道用户user_id
|crawlerFrequence|是	|int	|运行周期，单位/天
|crawlerServer|否	|string	|爬虫运行的服务器
|crawlerCmd|否	|string	|爬虫启动命令
|crawlerParams|否	|string	|爬虫启动参数
|lastRuntime|否	|datetime	|爬虫最后一次运行时间，默认1970年，格式/2019-09-20 17:09:07
|lastRuncode|否	|int	|最后一次运行出错代码，0为正常
|lastRunmessage|否	|string	|爬虫最后一次运行的反馈消息
|crawlerRuntimes|否	|int	|爬虫运行次数，默认0

    
### 返回参数
    {
        "code": 200,
        "msg": "success"
    }

--------------------------------------------------


## 接口描述
修改爬虫


### HTTP方法: PUT

### 请求URL: 
    http://127.0.0.1:8000/v1/crawler

## 请求示例:
    {
    	"crawlerName": "crawler",
    	"crawlerMaster": "yhb1",
    	"seriesId": "8f557978c31211e9a205482ae31bec7c",
    	"crawlerFrequence": 2
    }

### 请求参数

|参数|是否必选|类型|描述
|-|-|-|-
|seriesId|是	|string	|爬虫对应的期刊id，唯一索引
|crawlerName|是	|string	|爬虫名称，唯一索引
|crawlerMaster|是	|string	|爬虫编写者，国道用户user_id
|crawlerFrequence|是	|int	|运行周期，单位/天
|crawlerServer|否	|string	|爬虫运行的服务器
|crawlerCmd|否	|string	|爬虫启动命令
|crawlerParams|否	|string	|爬虫启动参数
|lastRuntime|否	|datetime	|爬虫最后一次运行时间，默认1970年，格式/2019-09-20 17:09:07
|lastRuncode|否	|int	|最后一次运行出错代码，0为正常
|lastRunmessage|否	|string	|爬虫最后一次运行的反馈消息
|crawlerRuntimes|否	|int	|爬虫运行次数，默认0

    
### 返回参数
    {
        "code": 200,
        "msg": "success"
    }

--------------------------------------------------


## 接口描述
删除爬虫


### HTTP方法: DELETE

### 请求URL: 
    http://127.0.0.1:8000/v1/crawler

## 请求示例:
    {
    	"scouterName": "crawler"
    }

### 请求参数

|参数|是否必选|类型|描述
|-|-|-|-
|seriesId|否	|string	|爬虫对应的期刊id，唯一索引
|crawlerName|否	|string	|爬虫名称，唯一索引

    
### 返回参数
    {
        "code": 200,
        "msg": "success"
    }

### 注
删除时，seriesId和scouterName提供任何一个即可

--------------------------------------------------


--------------------------------------------------


## 接口描述
上次出错的爬虫列表


### HTTP方法: GET

### 请求URL: 
    http://127.0.0.1:8000/v1/crawler/failure


    
### 返回参数
    {
        "data": {
            "count": 1,
            "pageSize": 100,
            "page": 1,
            "results": [
                {
                    "scouter_name": "scout5",
                    "scouter_master": "yhb",
                    "series_id": "2e048476-c312-11e9-810e-482ae31bec7c",
                    "scouter_frequence": 5,
                    "last_run_time": "1970",
                    "last_run_code": 0,
                    "last_run_message": "有错",
                    "scouter_server": null,
                    "scouter_cmd": null,
                    "scouter_params": null,
                    "scouter_run_times": 0
                }
            ]
        },
        "code": 200,
        "msg": "success"
    }
--------------------------------------------------


## 接口描述
未安排爬虫的期刊


### HTTP方法: GET

### 请求URL: 
    http://127.0.0.1:8000/v1/journal/crawler/empty


    
### 返回参数
    {
        "data": {
            "count": 1,
            "pageSize": 100,
            "page": 1,
            "results": [
                {
                    "series_id": "2e03c1ae-c312-11e9-93f2-482ae31bec7c",
                    "series_name": "Publishers Weekly"
                },
            ]
        },
        "code": 200,
        "msg": "success"
    }
--------------------------------------------------

## 接口描述
爬虫运行结果汇报


### HTTP方法: POST

### 请求URL: 
    http://127.0.0.1:8000/v1/crawler/report

### 请求示例

    insert_data = {
        'crawlerName': "",				        # 爬虫名称
        'seriesId': "",                         # 如果出错，出错在哪个刊上，可选项
        'lastRuncode': 0,						# 结果代码，0正常，>0为出错代码
        'lastRunmessage': "",					# 检查结果的消息，空为正常，非空为给管理员的提示
        'updateSeries': [		             # 本次更新了哪些刊
    		{
    			seriesId:"",			# 刊标识
    			lastVol:"",			# 最新数据的卷期
    			lastIssue:"",
    			lastYear:0,			# 或者最新数据的年月
    			lastMonth:0,
    			lastpublishTime:"",	# 如果能得到最新数据的出版时间
    			lastCrawlamount:0,			    # 本刊文献更新量
    		},
	    ]

    }

### 请求参数

|参数|是否必选|类型|描述
|-|-|-|-
|seriesId|否	|string	|如果出错，出错在哪个刊上，可选项
|crawlerName|是	|string	|爬虫名称
|lastRuncode|是	|int	|结果代码，0正常，>0为出错代码
|lastRunmessage|是	|string	|检查结果的消息，空为正常，非空为给管理员的提示
|updateSeries|是	|arry	|本次更新了哪些刊
|+seriesId|是	|string	|爬虫对应的期刊id
|+lastYear|否	|string	|以年月形式的刊的最新信息
|+lastMonth|否	|string	|以年月形式的刊的最新信息
|+lastVol|否	|string	|以卷期形式的刊的最新信息
|+lastIssue|否	|string	|以卷期形式的刊的最新信息
|+lastCrawlamount|是	|int	|本刊文献更新量
|+lastpublishTime|否	|string	|如果能得到最新数据的出版时间

### 返回参数
    {
        "code": 200,
        "msg": "success"
    }
--------------------------------------------------



### *注：失败统一返回状态码40000以及出错信息*